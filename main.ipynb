{"cells":[{"cell_type":"code","execution_count":132,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-13T22:37:11.313789Z","iopub.status.busy":"2024-03-13T22:37:11.312836Z","iopub.status.idle":"2024-03-13T22:37:11.322229Z","shell.execute_reply":"2024-03-13T22:37:11.321341Z","shell.execute_reply.started":"2024-03-13T22:37:11.313756Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from catboost import CatBoostClassifier, Pool\n","from lightgbm import LGBMClassifier\n","import random\n","import warnings\n","warnings.filterwarnings('ignore')\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","import seaborn as sns\n","from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, auc, f1_score\n","import tqdm\n","random.seed(42)\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-03-13T18:38:49.104282Z","iopub.status.busy":"2024-03-13T18:38:49.103194Z","iopub.status.idle":"2024-03-13T18:41:35.606889Z","shell.execute_reply":"2024-03-13T18:41:35.605562Z","shell.execute_reply.started":"2024-03-13T18:38:49.104246Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: /kaggle/input/lightautoml-038-dependecies\n","Processing /kaggle/input/lightautoml-038-dependecies/lightautoml-0.3.8-py3-none-any.whl\n","Processing /kaggle/input/lightautoml-038-dependecies/AutoWoE-1.3.2-py3-none-any.whl (from lightautoml==0.3.8)\n","Requirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\n","Processing /kaggle/input/lightautoml-038-dependecies/cmaes-0.10.0-py3-none-any.whl (from lightautoml==0.3.8)\n","Requirement already satisfied: holidays in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.24)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.1.2)\n","Processing /kaggle/input/lightautoml-038-dependecies/joblib-1.2.0-py3-none-any.whl (from lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/json2html-1.3.0.tar.gz (from lightautoml==0.3.8)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hProcessing /kaggle/input/lightautoml-038-dependecies/lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (from lightautoml==0.3.8)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.2.1)\n","Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.26.4)\n","Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.5.0)\n","Processing /kaggle/input/lightautoml-038-dependecies/pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/poetry_core-1.8.1-py3-none-any.whl (from lightautoml==0.3.8)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (6.0.1)\n","Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\n","Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.12.2)\n","Processing /kaggle/input/lightautoml-038-dependecies/statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (from lightautoml==0.3.8)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (4.66.1)\n","Processing /kaggle/input/lightautoml-038-dependecies/StrEnum-0.4.15-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (3.7.5)\n","Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (8.0.1)\n","Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (2023.3.post1)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (1.11.4)\n","Processing /kaggle/input/lightautoml-038-dependecies/sphinx-7.2.6-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\n","Requirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (0.2.4)\n","Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (0.20.1)\n","Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (5.18.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (1.16.0)\n","Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml==0.3.8) (0.42.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0->lightautoml==0.3.8) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->lightautoml==0.3.8) (3.2.0)\n","Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (0.5.6)\n","Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (21.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.12)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (69.0.3)\n","Processing /kaggle/input/lightautoml-038-dependecies/cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/lit-17.0.4.tar.gz (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml==0.3.8)\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: hijri-converter in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (2.3.1)\n","Requirement already satisfied: korean-lunar-calendar in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (0.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->lightautoml==0.3.8) (2.1.3)\n","Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (1.13.1)\n","Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (6.8.2)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (2.0.25)\n","Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->lightautoml==0.3.8) (1.3.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (4.47.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (3.1.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml==0.3.8) (3.0.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost>=0.26.1->lightautoml==0.3.8) (8.2.3)\n","Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.0)\n","Requirement already satisfied: pluggy<2.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.3.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.2.0)\n","Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.1)\n","Processing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Requirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.17.2)\n","Requirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (0.20.1)\n","Requirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.2.0)\n","Requirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.14.0)\n","Processing /kaggle/input/lightautoml-038-dependecies/alabaster-0.7.13-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Processing /kaggle/input/lightautoml-038-dependecies/imagesize-1.4.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\n","Requirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.31.0)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (2024.2.2)\n","Building wheels for collected packages: json2html, lit\n","  Building wheel for json2html (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7593 sha256=e1e7aaf9ec2a674e32da6c04a4fadeb32b4adf5cccc615173f65629d72481d31\n","  Stored in directory: /root/.cache/pip/wheels/03/04/0d/34912ecabd9128a537a032c0fc15c6c46e734fb5fe3a14536c\n","  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for lit: filename=lit-17.0.4-py3-none-any.whl size=93257 sha256=fb815d35a45b2102854bd91853d4dc844eed028dd2e9bd3e40b81dd853a16c7e\n","  Stored in directory: /root/.cache/pip/wheels/eb/c1/16/93f50cb09e1c8a4ba09c4156bca10e6be8f57108b0971e65e1\n","Successfully built json2html lit\n","Installing collected packages: StrEnum, lit, json2html, cmake, sphinxcontrib-jsmath, poetry-core, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, joblib, imagesize, cmaes, alabaster, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, statsmodels, lightgbm, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, triton, sphinx, torch, autowoe, lightautoml\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.3.2\n","    Uninstalling joblib-1.3.2:\n","      Successfully uninstalled joblib-1.3.2\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.1.4\n","    Uninstalling pandas-2.1.4:\n","      Successfully uninstalled pandas-2.1.4\n","  Attempting uninstall: statsmodels\n","    Found existing installation: statsmodels 0.14.1\n","    Uninstalling statsmodels-0.14.1:\n","      Successfully uninstalled statsmodels-0.14.1\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 4.2.0\n","    Uninstalling lightgbm-4.2.0:\n","      Successfully uninstalled lightgbm-4.2.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2\n","    Uninstalling torch-2.1.2:\n","      Successfully uninstalled torch-2.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cubinlinker, which is not installed.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires ptxcompiler, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\n","cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","fitter 1.7.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\n","libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","mizani 0.11.0 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","plotnine 0.13.0 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n","pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","xarray 2024.2.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed StrEnum-0.4.15 alabaster-0.7.13 autowoe-1.3.2 cmaes-0.10.0 cmake-3.27.7 imagesize-1.4.1 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8 lightgbm-3.2.1 lit-17.0.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pandas-1.5.3 poetry-core-1.8.1 sphinx-7.2.6 sphinxcontrib-applehelp-1.0.7 sphinxcontrib-devhelp-1.0.5 sphinxcontrib-htmlhelp-2.0.4 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.6 sphinxcontrib-serializinghtml-1.1.9 statsmodels-0.14.0 torch-2.0.0 triton-2.0.0\n","Looking in links: /kaggle/input/lightautoml-038-dependecies\n","Processing /kaggle/input/lightautoml-038-dependecies/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (1.26.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.16.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.5.3\n","    Uninstalling pandas-1.5.3:\n","      Successfully uninstalled pandas-1.5.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cubinlinker, which is not installed.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires ptxcompiler, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\n","cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\n","fitter 1.7.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\n","libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","lightautoml 0.3.8 requires pandas<2.0.0, but you have pandas 2.0.3 which is incompatible.\n","mizani 0.11.0 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","plotnine 0.13.0 requires pandas>=2.1.0, but you have pandas 2.0.3 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","xarray 2024.2.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-2.0.3\n"]}],"source":["!pip install -U lightautoml"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:15.116970Z","iopub.status.busy":"2024-03-13T22:37:15.116194Z","iopub.status.idle":"2024-03-13T22:37:15.123291Z","shell.execute_reply":"2024-03-13T22:37:15.122399Z","shell.execute_reply.started":"2024-03-13T22:37:15.116937Z"},"trusted":true},"outputs":[],"source":["import random\n","import torch\n","import torch.nn as nn\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from lightautoml.automl.presets.tabular_presets import TabularAutoML\n","from lightautoml.tasks import Task\n","import os\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","seed_everything()"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:17.307665Z","iopub.status.busy":"2024-03-13T22:37:17.306705Z","iopub.status.idle":"2024-03-13T22:37:21.802155Z","shell.execute_reply":"2024-03-13T22:37:21.801309Z","shell.execute_reply.started":"2024-03-13T22:37:17.307621Z"},"trusted":true},"outputs":[],"source":["df = pd.read_parquet('/kaggle/input/purple-hack/train_ai_comp_final_dp.parquet')"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:21.804278Z","iopub.status.busy":"2024-03-13T22:37:21.803979Z","iopub.status.idle":"2024-03-13T22:37:22.914827Z","shell.execute_reply":"2024-03-13T22:37:22.913957Z","shell.execute_reply.started":"2024-03-13T22:37:21.804252Z"},"trusted":true},"outputs":[],"source":["test = pd.read_parquet('/kaggle/input/purple-hack-with-test/test_sber.parquet')"]},{"cell_type":"code","execution_count":136,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:22.916355Z","iopub.status.busy":"2024-03-13T22:37:22.916057Z","iopub.status.idle":"2024-03-13T22:37:24.161969Z","shell.execute_reply":"2024-03-13T22:37:24.161143Z","shell.execute_reply.started":"2024-03-13T22:37:22.916329Z"},"trusted":true},"outputs":[],"source":["for col in df.columns:\n","    if df[col].dtype == 'int64':\n","        df[col] = df[col].astype('int32')\n","    elif df[col].dtype == 'float64':\n","        df[col] = df[col].astype('float32')\n","    elif df[col].dtype == 'object':\n","        if len(df[col].unique()) / len(df[col]) < 0.5:\n","            df[col] = df[col].astype('category')\n"]},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:24.164924Z","iopub.status.busy":"2024-03-13T22:37:24.164035Z","iopub.status.idle":"2024-03-13T22:37:24.174400Z","shell.execute_reply":"2024-03-13T22:37:24.173530Z","shell.execute_reply.started":"2024-03-13T22:37:24.164892Z"},"trusted":true},"outputs":[],"source":["# Удаление фичей, которые коррелируют друг с другом больше, чем на 0.9\n","def get_correlated_feats(corr_matrix, feat_stats, greater_is_better=True, corr_threshold=0.95):\n","    cols = corr_matrix.columns.to_list()\n","    dropped = {col:0 for col in cols}\n","    for col in tqdm.tqdm(cols, desc='Get correlated features'):\n","        if dropped[col] == 0:\n","            columns_to_check = corr_matrix.index.values[np.abs(corr_matrix[col]) >= corr_threshold]\n","            if len(columns_to_check) > 1:\n","                if feat_stats is None:\n","                    bad_cols = columns_to_check[1:]\n","                else:\n","                    sel_stats = feat_stats.loc[columns_to_check]\n","                    if greater_is_better:\n","                        bad_cond = np.abs(sel_stats) < np.abs(sel_stats).max()\n","                    else:\n","                        bad_cond = np.abs(sel_stats) > np.abs(sel_stats).min()\n","                        \n","                    bad_cols = sel_stats[bad_cond].index.to_list()\n","                    norm_cols = sel_stats[~bad_cond].index.to_list()\n","                    if len(norm_cols) > 1:\n","                        for norm_col in norm_cols[1:]:\n","                            dropped[norm_col] += 1\n","                            \n","                for bad_col in bad_cols:\n","                    dropped[bad_col] += 1\n","    high_corr_cols = [c for c in dropped.keys() if dropped[c] > 0]\n","    return high_corr_cols"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:24.175835Z","iopub.status.busy":"2024-03-13T22:37:24.175546Z","iopub.status.idle":"2024-03-13T22:37:39.412978Z","shell.execute_reply":"2024-03-13T22:37:39.412067Z","shell.execute_reply.started":"2024-03-13T22:37:24.175810Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["194\n"]}],"source":["clean_df = df.copy()\n","nan_percentage = (clean_df == 0).mean()\n","cols_to_drop = list(nan_percentage[nan_percentage > 0.95].index)\n","\n","ignore_features = ['id', 'target', 'sample_ml_new', 'feature756']+cols_to_drop\n","print(len(ignore_features))\n","clean_df = clean_df.drop(columns=ignore_features)\n","\n","corr_mx = pd.DataFrame(np.corrcoef(clean_df.values, rowvar=False), columns=clean_df.columns, index=clean_df.columns)"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:39.414513Z","iopub.status.busy":"2024-03-13T22:37:39.414204Z","iopub.status.idle":"2024-03-13T22:37:39.709338Z","shell.execute_reply":"2024-03-13T22:37:39.708470Z","shell.execute_reply.started":"2024-03-13T22:37:39.414488Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Get correlated features: 100%|██████████| 886/886 [00:00<00:00, 3107.48it/s]\n"]},{"data":{"text/plain":["275"]},"execution_count":139,"metadata":{},"output_type":"execute_result"}],"source":["corr_feats = get_correlated_feats(corr_mx, feat_stats=nan_percentage, greater_is_better=False, corr_threshold=0.95)\n","len(corr_feats)"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:39.710788Z","iopub.status.busy":"2024-03-13T22:37:39.710474Z","iopub.status.idle":"2024-03-13T22:37:39.997600Z","shell.execute_reply":"2024-03-13T22:37:39.996591Z","shell.execute_reply.started":"2024-03-13T22:37:39.710764Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Было: (519615, 1079)\n","Стало: (519615, 611)\n"]}],"source":["df_no_corr = clean_df.drop(columns=corr_feats)\n","print(\"Было:\", df.shape)\n","print(\"Стало:\", df_no_corr.shape)"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:39.999827Z","iopub.status.busy":"2024-03-13T22:37:39.999062Z","iopub.status.idle":"2024-03-13T22:37:42.707173Z","shell.execute_reply":"2024-03-13T22:37:42.706380Z","shell.execute_reply.started":"2024-03-13T22:37:39.999787Z"},"trusted":true},"outputs":[],"source":["final_feats = df_no_corr.columns\n","\n","X = df[final_feats].drop(columns = ['feature642'])\n","y = df['target']"]},{"cell_type":"code","execution_count":143,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-03-13T22:37:43.067713Z","iopub.status.busy":"2024-03-13T22:37:43.067271Z","iopub.status.idle":"2024-03-13T22:37:43.109312Z","shell.execute_reply":"2024-03-13T22:37:43.108318Z","shell.execute_reply.started":"2024-03-13T22:37:43.067660Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/1557518016.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X['sin341'] = np.sin(X['feature341'])\n","/tmp/ipykernel_34/1557518016.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X['log940'] = np.log1p(X['feature940'])\n","/tmp/ipykernel_34/1557518016.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  X['new1'] = (X['feature1004'] * X['feature994'])\n"]}],"source":["X['sin341'] = np.sin(X['feature341'])\n","X['log940'] = np.log1p(X['feature940'])\n","X['new1'] = (X['feature1004'] * X['feature994'])\n","\n","test['sin341'] = np.sin(test['feature341'])\n","test['log940'] = np.log1p(test['feature940'])\n","test['new1'] = (test['feature1004'] * test['feature994'])"]},{"cell_type":"code","execution_count":144,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:43.110782Z","iopub.status.busy":"2024-03-13T22:37:43.110476Z","iopub.status.idle":"2024-03-13T22:37:44.136587Z","shell.execute_reply":"2024-03-13T22:37:44.135805Z","shell.execute_reply.started":"2024-03-13T22:37:43.110755Z"},"trusted":true},"outputs":[],"source":["X = X.reset_index(drop = True)\n","y = y.reset_index(drop = True)"]},{"cell_type":"code","execution_count":145,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:44.138359Z","iopub.status.busy":"2024-03-13T22:37:44.137922Z","iopub.status.idle":"2024-03-13T22:37:47.001261Z","shell.execute_reply":"2024-03-13T22:37:47.000436Z","shell.execute_reply.started":"2024-03-13T22:37:44.138324Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import PolynomialFeatures\n","\n","poly = PolynomialFeatures(degree=2, interaction_only=True)\n","poly_features = poly.fit_transform(X[['feature1004', 'feature318', 'feature341', 'feature994', 'feature952',\n","        'feature944', 'feature320', 'feature1000', 'feature943', 'feature993', 'new1', 'sin341', 'log940']])\n","poly_feature_names = [f'poly_{i}' for i in range(poly_features.shape[1])]\n","X_poly = pd.DataFrame(poly_features, columns=poly_feature_names)\n","X = pd.concat([X, X_poly], axis=1)\n","\n","\n","poly = PolynomialFeatures(degree=2, interaction_only=True)\n","poly_features = poly.fit_transform(test[['feature1004', 'feature318', 'feature341', 'feature994', 'feature952',\n","        'feature944', 'feature320', 'feature1000', 'feature943', 'feature993', 'new1', 'sin341', 'log940']])\n","poly_feature_names = [f'poly_{i}' for i in range(poly_features.shape[1])]\n","test_poly = pd.DataFrame(poly_features, columns=poly_feature_names)\n","\n","test = pd.concat([test, test_poly], axis=1)"]},{"cell_type":"code","execution_count":146,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:47.002847Z","iopub.status.busy":"2024-03-13T22:37:47.002434Z","iopub.status.idle":"2024-03-13T22:37:47.131890Z","shell.execute_reply":"2024-03-13T22:37:47.131083Z","shell.execute_reply.started":"2024-03-13T22:37:47.002814Z"},"trusted":true},"outputs":[],"source":["feats2 = [\n","    'feature208', 'feature310', 'poly_63', 'feature998', 'poly_74', \n","    'feature534', 'poly_53', 'feature950', 'poly_76', 'feature992', \n","    'poly_14', 'feature943', 'feature357', 'feature341', 'feature920', \n","    'feature944', 'feature572', 'feature210', 'poly_19', 'feature952', \n","    'feature309', 'feature990', 'feature817', 'feature945', 'feature999',\n","    'feature156', 'poly_81', 'poly_11', 'feature940', 'feature342', 'feature187', \n","    'feature191', 'feature1', 'poly_1', 'feature993', 'feature35', 'poly_58', \n","    'feature356', 'poly_7', 'feature444', 'feature320', 'feature192', 'poly_88', \n","    'poly_83', 'feature928', 'feature193', 'feature559', 'poly_46', 'feature948', \n","    'feature101', 'poly_4', 'poly_31', 'feature1056', 'poly_5', 'feature994', \n","    'feature688', 'feature941', 'feature1000', 'feature139', 'poly_34', 'poly_17', \n","    'feature494', 'feature869', 'feature861', 'feature190', 'feature898', 'feature551', \n","    'feature935', 'feature350', 'feature939', 'poly_57', 'sin341', 'feature922', 'poly_23', \n","    'feature287', 'feature930', 'feature195', 'feature862', 'poly_65', 'feature543', \n","    'feature349', 'feature532', 'feature713', 'feature212', 'feature946', 'feature782', \n","    'poly_79', 'poly_82', 'poly_3', 'poly_55', 'feature936', 'poly_71', 'poly_56', \n","    'feature1036', 'feature985', 'poly_78', 'poly_28', 'feature758', 'feature472', \n","    'feature1003', 'feature997', 'poly_22', 'feature318', 'poly_36', 'poly_50', 'poly_27', \n","    'feature1002', 'feature112', 'feature942', 'feature988', 'poly_52', 'feature1069', \n","    'feature1004', 'new1', 'feature270', 'feature951', 'poly_77', 'feature43', 'poly_25', \n","    'log940', 'feature435', 'feature548', 'poly_2', 'poly_29', 'feature989', 'feature546', \n","    'feature949', 'feature94', 'feature47', 'poly_30', 'feature497', 'feature128', 'poly_68'\n","]\n","X = X[feats2]\n","test = test[feats2]"]},{"cell_type":"code","execution_count":149,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:56.588389Z","iopub.status.busy":"2024-03-13T22:37:56.588018Z","iopub.status.idle":"2024-03-13T22:37:56.639969Z","shell.execute_reply":"2024-03-13T22:37:56.639221Z","shell.execute_reply.started":"2024-03-13T22:37:56.588358Z"},"trusted":true},"outputs":[],"source":["automl_production = TabularAutoML(\n","    task=Task('binary', metric='auc', loss='logloss'), \n","    reader_params={'n_jobs': 4, 'cv' : 2, 'random_state': 42, 'advanced_roles': False},\n","    debug=True,\n","    general_params={\"use_algos\": [['denselight', 'autoint']]}, \n","    nn_params={\n","        \"0\": {\n","            \"bs\": 1024,\n","            'lr': 0.0006672367170464204,\n","            'weight_decay': 2.9204338471814107e-05,\n","            'weight_decay_bin': 1,\n","            \"freeze_defaults\": True,\n","            \"n_epochs\": 15,\n","            'path_to_save': '/kaggle/working/denselight'\n","        },\n","        '1': {\n","            \"bs\": 1024,\n","            'lr': 1e-3,\n","            \"freeze_defaults\": True,\n","            \"n_epochs\": 10,\n","            'path_to_save': '/kaggle/working/autoint'\n","        }\n","    }\n",")\n"]},{"cell_type":"code","execution_count":150,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T22:37:59.669644Z","iopub.status.busy":"2024-03-13T22:37:59.669011Z","iopub.status.idle":"2024-03-13T22:37:59.681168Z","shell.execute_reply":"2024-03-13T22:37:59.680223Z","shell.execute_reply.started":"2024-03-13T22:37:59.669612Z"},"trusted":true},"outputs":[],"source":["import joblib\n","class SoftVotingClassifier():\n","    def __init__(self, estimators):\n","        self.estimators = estimators\n","    \n","    def fit(self, X, y):\n","        self.estimators_ = [estimator for estimator in self.estimators]\n","        for i, estimator in enumerate(self.estimators_):\n","            if str(type(estimator)) == \"<class 'lightautoml.automl.presets.tabular_presets.TabularAutoML'>\":\n","                df_train = pd.concat([X, y], axis=1)\n","                self.estimators_[i].fit_predict(df_train, roles =  {'target': 'target'}, verbose = 3)\n","            else:\n","                estimator.fit(X, y)\n","                joblib.dump(estimator, 'cat_' + str(i) + '.pkl')\n","        return self\n","    \n","    def predict_proba(self, X):\n","        l = len(self.estimators_)\n","        w = [0.4, 0.15, 0.15, 0.3]\n","        all_probabilities = [estimator.predict_proba(X)[:, 1] * 2/9 if str(type(estimator)) != \"<class 'lightautoml.automl.presets.tabular_presets.TabularAutoML'>\" else estimator.predict(X).data.flatten() * 1/3 for i, estimator in enumerate(self.estimators_)]\n","        probabilities = [estimator.predict_proba(X)[:, 1] if str(type(estimator)) != \"<class 'lightautoml.automl.presets.tabular_presets.TabularAutoML'>\" else estimator.predict(X).data.flatten() for i, estimator in enumerate(self.estimators_)]\n","\n","        mean_probabilities = np.sum(all_probabilities, axis=0)\n","        return mean_probabilities, probabilities\n","    \n","    def predict(self, X):\n","        probabilities = self.predict_proba(X)\n","        return np.argmax(probabilities, axis=1)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T20:22:48.773646Z","iopub.status.busy":"2024-03-13T20:22:48.773293Z","iopub.status.idle":"2024-03-13T20:22:48.778747Z","shell.execute_reply":"2024-03-13T20:22:48.777752Z","shell.execute_reply.started":"2024-03-13T20:22:48.773618Z"},"trusted":true},"outputs":[],"source":["params = {\n","    'iterations': 2654, \n","    'learning_rate': 0.03354989749053529, \n","    'depth': 5, 'l2_leaf_reg': 9.633986278110502, \n","    'random_strength': 8.976484608530859, \n","    'bagging_temperature': 0.44428949970755705, \n","    'border_count': 158, \n","    'verbose': 500,  \n","    'task_type': 'GPU', \n","    'class_weights': [1, 10]\n","}\n","# 0.7658591942913879"]},{"cell_type":"code","execution_count":154,"metadata":{"execution":{"iopub.execute_input":"2024-03-13T23:01:22.638500Z","iopub.status.busy":"2024-03-13T23:01:22.638126Z","iopub.status.idle":"2024-03-13T23:22:11.784682Z","shell.execute_reply":"2024-03-13T23:22:11.783654Z","shell.execute_reply.started":"2024-03-13T23:01:22.638469Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0:\tlearn: 0.6820260\ttotal: 13.2ms\tremaining: 34.9s\n","500:\tlearn: 0.4891738\ttotal: 5.81s\tremaining: 25s\n","1000:\tlearn: 0.4728566\ttotal: 11.8s\tremaining: 19.4s\n","1500:\tlearn: 0.4604504\ttotal: 17.6s\tremaining: 13.5s\n","2000:\tlearn: 0.4497023\ttotal: 23.3s\tremaining: 7.62s\n","2500:\tlearn: 0.4394678\ttotal: 29.3s\tremaining: 1.79s\n","2653:\tlearn: 0.4364880\ttotal: 31.1s\tremaining: 0us\n","0:\tlearn: 0.6814623\ttotal: 12.2ms\tremaining: 32.4s\n","500:\tlearn: 0.4892420\ttotal: 5.85s\tremaining: 25.1s\n","1000:\tlearn: 0.4730384\ttotal: 11.7s\tremaining: 19.4s\n","1500:\tlearn: 0.4604896\ttotal: 17.6s\tremaining: 13.5s\n","2000:\tlearn: 0.4494862\ttotal: 23.6s\tremaining: 7.69s\n","2500:\tlearn: 0.4394482\ttotal: 29.6s\tremaining: 1.81s\n","2653:\tlearn: 0.4365051\ttotal: 31.4s\tremaining: 0us\n","0:\tlearn: 0.6818211\ttotal: 13ms\tremaining: 34.4s\n","500:\tlearn: 0.4889623\ttotal: 5.81s\tremaining: 25s\n","1000:\tlearn: 0.4728696\ttotal: 11.6s\tremaining: 19.2s\n","1500:\tlearn: 0.4604591\ttotal: 17.6s\tremaining: 13.5s\n","2000:\tlearn: 0.4495535\ttotal: 23.4s\tremaining: 7.65s\n","2500:\tlearn: 0.4395760\ttotal: 29.3s\tremaining: 1.79s\n","2653:\tlearn: 0.4366302\ttotal: 31.1s\tremaining: 0us\n","[23:03:03] Stdout logging level is INFO3.\n","[23:03:03] Task: binary\n","\n","[23:03:03] Start automl preset with listed constraints:\n","[23:03:03] - time: 3600.00 seconds\n","[23:03:03] - CPU: 4 cores\n","[23:03:03] - memory: 16 GB\n","\n","[23:03:03] \u001b[1mTrain data shape: (519615, 134)\u001b[0m\n","\n","[23:03:04] Layer \u001b[1m1\u001b[0m train process start. Time left 3598.87 secs\n","[23:03:06] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m ...\n","[23:03:06] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m =====\n","[23:03:13] Epoch: 0, train loss: 0.14309145510196686, val loss: 0.14070259034633636, val metric: 0.7333274651350232\n","[23:03:19] Epoch: 1, train loss: 0.139983668923378, val loss: 0.14002786576747894, val metric: 0.7390378145344378\n","[23:03:25] Epoch: 2, train loss: 0.1391160786151886, val loss: 0.1398662030696869, val metric: 0.7407652934559421\n","[23:03:31] Epoch: 3, train loss: 0.1386030614376068, val loss: 0.13977716863155365, val metric: 0.7422085372005709\n","[23:03:37] Epoch: 4, train loss: 0.13807740807533264, val loss: 0.13968022167682648, val metric: 0.7425295811394512\n","[23:03:43] Epoch: 5, train loss: 0.13772691786289215, val loss: 0.13974793255329132, val metric: 0.7430217385183119\n","[23:03:49] Epoch: 6, train loss: 0.1373622566461563, val loss: 0.13955730199813843, val metric: 0.7427701066919401\n","[23:03:56] Epoch: 7, train loss: 0.13700997829437256, val loss: 0.13965731859207153, val metric: 0.7433460633327023\n","[23:04:02] Epoch: 8, train loss: 0.13656924664974213, val loss: 0.13968636095523834, val metric: 0.7434267081053603\n","[23:04:08] Epoch: 9, train loss: 0.1362033188343048, val loss: 0.13980886340141296, val metric: 0.7432030638394156\n","[23:04:14] Epoch: 10, train loss: 0.13599945604801178, val loss: 0.14006578922271729, val metric: 0.7428816706696599\n","[23:04:20] Epoch: 11, train loss: 0.13556940853595734, val loss: 0.13969889283180237, val metric: 0.7438682582270846\n","[23:04:26] Epoch: 12, train loss: 0.13543733954429626, val loss: 0.13979709148406982, val metric: 0.7440107642325993\n","[23:04:32] Epoch: 13, train loss: 0.13434337079524994, val loss: 0.1397472321987152, val metric: 0.7444388218129988\n","[23:04:38] Epoch: 14, train loss: 0.13391470909118652, val loss: 0.13997887074947357, val metric: 0.7425568932761697\n","[23:04:41] Early stopping: val loss: 0.13942505419254303, val metric: 0.7442245774986892\n","[23:04:41] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m =====\n","[23:04:48] Epoch: 0, train loss: 0.14335328340530396, val loss: 0.14020617306232452, val metric: 0.7394271407901104\n","[23:04:54] Epoch: 1, train loss: 0.1405409872531891, val loss: 0.1398104429244995, val metric: 0.7418314687121101\n","[23:05:00] Epoch: 2, train loss: 0.13956083357334137, val loss: 0.13972441852092743, val metric: 0.7444950075207984\n","[23:05:06] Epoch: 3, train loss: 0.13912291824817657, val loss: 0.13948343694210052, val metric: 0.745667890309029\n","[23:05:13] Epoch: 4, train loss: 0.13870449364185333, val loss: 0.13925385475158691, val metric: 0.7473483748666705\n","[23:05:19] Epoch: 5, train loss: 0.13826027512550354, val loss: 0.13941238820552826, val metric: 0.7469573099318887\n","[23:05:25] Epoch: 6, train loss: 0.13777419924736023, val loss: 0.13900476694107056, val metric: 0.7478020917329515\n","[23:05:31] Epoch: 7, train loss: 0.13750094175338745, val loss: 0.13923417031764984, val metric: 0.7465159262077659\n","[23:05:37] Epoch: 8, train loss: 0.13701707124710083, val loss: 0.13963808119297028, val metric: 0.7456408872414966\n","[23:05:43] Epoch: 9, train loss: 0.13673335313796997, val loss: 0.13928472995758057, val metric: 0.7476677785930478\n","[23:05:49] Epoch: 10, train loss: 0.13637320697307587, val loss: 0.13935905694961548, val metric: 0.7460364022280608\n","[23:05:55] Epoch: 11, train loss: 0.13619950413703918, val loss: 0.13898371160030365, val metric: 0.7479235323239557\n","[23:06:01] Epoch: 12, train loss: 0.13575246930122375, val loss: 0.13922907412052155, val metric: 0.7477246628560579\n","[23:06:07] Epoch: 13, train loss: 0.1352776288986206, val loss: 0.13923311233520508, val metric: 0.7466328146796043\n","[23:06:13] Epoch: 14, train loss: 0.1350681036710739, val loss: 0.13953399658203125, val metric: 0.7455791379818775\n","[23:06:16] Early stopping: val loss: 0.13880601525306702, val metric: 0.7492645732796207\n","[23:06:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m finished. score = \u001b[1m0.7467252724827812\u001b[0m\n","[23:06:17] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m fitting and predicting completed\n","[23:06:17] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_autoint_1\u001b[0m ...\n","[23:06:17] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_autoint_1\u001b[0m =====\n","[23:07:03] Epoch: 0, train loss: 0.14255312085151672, val loss: 0.140359029173851, val metric: 0.7362297459554533\n","[23:07:49] Epoch: 1, train loss: 0.13954727351665497, val loss: 0.14010323584079742, val metric: 0.7416463026203153\n","[23:08:34] Epoch: 2, train loss: 0.13844367861747742, val loss: 0.13977184891700745, val metric: 0.7432962047042672\n","[23:09:20] Epoch: 3, train loss: 0.13757997751235962, val loss: 0.13961434364318848, val metric: 0.7433193379124667\n","[23:10:05] Epoch: 4, train loss: 0.13674163818359375, val loss: 0.1411179155111313, val metric: 0.7415894210494085\n","[23:10:51] Epoch: 5, train loss: 0.13599291443824768, val loss: 0.14096449315547943, val metric: 0.7425835058745937\n","[23:11:36] Epoch: 6, train loss: 0.13493505120277405, val loss: 0.14231890439987183, val metric: 0.7447283841602291\n","[23:12:22] Epoch: 7, train loss: 0.13407811522483826, val loss: 0.14549267292022705, val metric: 0.7401136267049325\n","[23:13:08] Epoch: 8, train loss: 0.13308773934841156, val loss: 0.1411316990852356, val metric: 0.7387118247370892\n","[23:13:53] Epoch: 9, train loss: 0.13185954093933105, val loss: 0.1427309513092041, val metric: 0.7318562445954073\n","[23:14:11] Early stopping: val loss: 0.13923151791095734, val metric: 0.744531851793818\n","[23:14:12] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_autoint_1\u001b[0m =====\n","[23:14:58] Epoch: 0, train loss: 0.14336203038692474, val loss: 0.1404721587896347, val metric: 0.7417189013081668\n","[23:15:44] Epoch: 1, train loss: 0.1399778574705124, val loss: 0.13959373533725739, val metric: 0.7445540918311842\n","[23:16:29] Epoch: 2, train loss: 0.1389486938714981, val loss: 0.14028377830982208, val metric: 0.7421721584405584\n","[23:17:14] Epoch: 3, train loss: 0.13798291981220245, val loss: 0.13917852938175201, val metric: 0.7461155890756671\n","[23:18:00] Epoch: 4, train loss: 0.1372390240430832, val loss: 0.13894307613372803, val metric: 0.7486863624141156\n","[23:18:45] Epoch: 5, train loss: 0.1364343911409378, val loss: 0.13945692777633667, val metric: 0.7470775037504251\n","[23:19:30] Epoch: 6, train loss: 0.13559086620807648, val loss: 0.13965709507465363, val metric: 0.743437516646781\n","[23:20:16] Epoch: 7, train loss: 0.13441556692123413, val loss: 0.13976195454597473, val metric: 0.7412440513255578\n","[23:21:01] Epoch: 8, train loss: 0.13308914005756378, val loss: 0.14056438207626343, val metric: 0.7404185180548751\n","[23:21:47] Epoch: 9, train loss: 0.13173092901706696, val loss: 0.14040504395961761, val metric: 0.7422809385847152\n","[23:22:05] Early stopping: val loss: 0.13853813707828522, val metric: 0.7501483155359772\n","[23:22:05] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_autoint_1\u001b[0m finished. score = \u001b[1m0.7473540245698203\u001b[0m\n","[23:22:05] \u001b[1mLvl_0_Pipe_0_Mod_1_TorchNN_autoint_1\u001b[0m fitting and predicting completed\n","[23:22:05] Time left 2457.39 secs\n","\n","[23:22:05] \u001b[1mLayer 1 training completed.\u001b[0m\n","\n","[23:22:06] Blending: optimization starts with equal weights and score \u001b[1m0.7497686370824627\u001b[0m\n","[23:22:08] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7497747560042175\u001b[0m, weights = \u001b[1m[0.47523627 0.5247637 ]\u001b[0m\n","[23:22:11] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7497747560042175\u001b[0m, weights = \u001b[1m[0.47523627 0.5247637 ]\u001b[0m\n","[23:22:11] Blending: no score update. Terminated\n","\n","[23:22:11] \u001b[1mAutoml preset training completed in 1148.53 seconds\u001b[0m\n","\n","[23:22:11] Model description:\n","Final prediction for new objects (level 0) = \n","\t 0.47524 * (2 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_denselight_0) +\n","\t 0.52476 * (2 averaged models Lvl_0_Pipe_0_Mod_1_TorchNN_autoint_1) \n","\n"]},{"data":{"text/plain":["<__main__.SoftVotingClassifier at 0x7e6d3c3d17b0>"]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.ensemble import VotingClassifier\n","from sklearn.base import ClassifierMixin, TransformerMixin, clone\n","\n","model = SoftVotingClassifier(\n","            [CatBoostClassifier(**params, random_seed=42 + i) for i in range(3)]*1 + [LGBMClassifier(is_unbalance=True, max_depth = 6, random_seed = 42)]*0 + [automl_production]*1\n","        )\n","model.fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import csv\n","\n","pred = model.predict_proba(test)[0]\n","pred_binary = (pred >= 0.405).astype(int)\n","\n","submission = pd.read_csv(\"/kaggle/input/purple-hack-with-test/sample_submission.csv\")\n","submission[\"target_prob\"] = pred\n","submission[\"target_bin\"] = pred_binary\n","submission.head(3)\n","\n","with open(\"submission.csv\", \"w\", newline=\"\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow(submission.columns)\n","    writer.writerows(submission.values)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4565798,"sourceId":7798384,"sourceType":"datasetVersion"},{"datasetId":4579972,"sourceId":7817524,"sourceType":"datasetVersion"},{"datasetId":4581109,"sourceId":7819157,"sourceType":"datasetVersion"},{"sourceId":150384981,"sourceType":"kernelVersion"},{"sourceId":160761304,"sourceType":"kernelVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
